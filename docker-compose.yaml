services:
  insanely-fast-whisper:
    build:
      context: .
      dockerfile: Dockerfile.v2

    image: ghrc.io/beecave-homelab/insanely-fast-whisper-rocm:rocm6.1
    container_name: insanely-fast-whisper-rocm
    restart: unless-stopped

    devices:
      - "/dev/kfd:/dev/kfd"
      - "/dev/dri:/dev/dri"
    stdin_open: true
    tty: true
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    group_add:
      - video
    ipc: host
    shm_size: 8G

    volumes:
      - ./data:/data

    # command: ["python", "-c", "import torch; print('GPU is available' if torch.cuda.is_available() else 'GPU is not available')"]
    # command: ["python", "testing/test_cuda.py"]
    command: ["/bin/bash", "testing/test_insanely_fast_whisper.sh"]

    ports:
      - 7860:7860
